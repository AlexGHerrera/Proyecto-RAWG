# RAWG Game Success Prediction - Documentaci√≥n del Proyecto

## üìã √çndice
1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [An√°lisis Exploratorio de Datos (EDA)](#an√°lisis-exploratorio-de-datos-eda)
3. [Selecci√≥n de Features](#selecci√≥n-de-features)
4. [Definici√≥n de Variables Target](#definici√≥n-de-variables-target)
5. [Selecci√≥n de Modelos](#selecci√≥n-de-modelos)
6. [Pipeline de Entrenamiento](#pipeline-de-entrenamiento)
7. [Resultados y Conclusiones](#resultados-y-conclusiones)
8. [Archivos del Proyecto](#archivos-del-proyecto)

---

## üéØ Resumen Ejecutivo

### Objetivo del Proyecto
Desarrollar un modelo predictivo que permita a dise√±adores de videojuegos estimar el **√©xito potencial** de un juego antes de su lanzamiento, utilizando √∫nicamente caracter√≠sticas de dise√±o que est√°n disponibles en la fase de planificaci√≥n.

### Problema de Negocio
Los estudios de videojuegos necesitan tomar decisiones informadas sobre:
- **Inversi√≥n en desarrollo**: ¬øVale la pena invertir recursos en este concepto?
- **Estrategia de marketing**: ¬øQu√© nivel de promoci√≥n necesita el juego?
- **Expectativas comerciales**: ¬øCu√°les son las proyecciones realistas de √©xito?

### Soluci√≥n Propuesta
Un modelo de **regresi√≥n** que predice un `success_score` (0-1) basado en 6 caracter√≠sticas de dise√±o que un desarrollador puede especificar antes del desarrollo.

---

## üîç An√°lisis Exploratorio de Datos (EDA)

### Fuentes de Datos
El proyecto utiliza datos de **RAWG.io**, una base de datos masiva de videojuegos que contiene:

#### Tabla Principal: `games`
- **Registros**: ~900,000 juegos
- **Informaci√≥n b√°sica**: nombre, fecha de lanzamiento, rating, popularidad
- **M√©tricas de engagement**: reviews, sugerencias, usuarios que agregaron el juego

#### Tabla de Comportamiento: `game_added_by_status`
- **Estructura**: `id_game`, `status`, `count`
- **Status disponibles**: `owned`, `beaten`, `dropped`, `playing`, `toplay`, `yet`
- **Registros**: ~291,000 entradas para ~109,000 juegos √∫nicos

#### Tablas de Relaci√≥n:
- `game_genres`: G√©neros por juego
- `game_platforms`: Plataformas por juego  
- `game_tags`: Tags descriptivos por juego

### Hallazgos Clave del EDA

#### 1. Calidad de Datos
```sql
-- An√°lisis de completitud
Total juegos en BD: ~900,000
Con fecha de lanzamiento: ~850,000 (94%)
Con rating v√°lido: ~400,000 (44%)
Con engagement (added > 0): ~380,000 (42%)
Rango temporal 2010-2024: ~76,000 (8.4%)
```

#### 2. Distribuci√≥n de Engagement
- **owned**: M√©trica m√°s com√∫n (~180,000 registros)
- **beaten**: Indicador clave de satisfacci√≥n (~85,000 registros)
- **dropped**: Indicador de abandono (~45,000 registros)
- **playing**: Estado activo (~35,000 registros)

#### 3. Correlaciones Importantes
```
rating vs beaten: 0.456 (correlaci√≥n moderada-fuerte)
rating vs retention_rate: 0.523 (correlaci√≥n fuerte)
added vs beaten: 0.789 (correlaci√≥n muy fuerte)
owned vs beaten: 0.634 (correlaci√≥n fuerte)
```

#### 4. Distribuci√≥n Temporal
- **Pico de datos**: 2015-2020
- **Datos recientes**: Mejor calidad y completitud
- **Filtro aplicado**: 2010-2024 para relevancia actual

---

## üéØ Selecci√≥n de Features

### Criterios de Selecci√≥n
Las features seleccionadas deben cumplir:
1. **Disponibilidad temprana**: Conocidas en fase de dise√±o
2. **Controlabilidad**: El dise√±ador puede influir en ellas
3. **Relevancia predictiva**: Correlaci√≥n significativa con el √©xito
4. **Estabilidad**: No cambian durante el desarrollo

### Features de Dise√±o Seleccionadas

#### 1. **`n_genres`** - N√∫mero de G√©neros
- **Rango**: 1-8 g√©neros por juego
- **Justificaci√≥n**: Los g√©neros definen la audiencia objetivo
- **Correlaci√≥n con √©xito**: 0.234
- **Ejemplo**: Acci√≥n (1), Acci√≥n+RPG (2), Acci√≥n+RPG+Aventura (3)

#### 2. **`n_platforms`** - N√∫mero de Plataformas
- **Rango**: 1-15 plataformas por juego
- **Justificaci√≥n**: M√°s plataformas = mayor alcance potencial
- **Correlaci√≥n con √©xito**: 0.312
- **Ejemplo**: Solo PC (1), PC+PlayStation+Xbox (3)

#### 3. **`n_tags`** - N√∫mero de Tags Descriptivos
- **Rango**: 0-50 tags por juego
- **Justificaci√≥n**: Tags indican riqueza de caracter√≠sticas
- **Correlaci√≥n con √©xito**: 0.189
- **Ejemplo**: "Singleplayer", "Story Rich", "Atmospheric"

#### 4. **`esrb_rating_id`** - Clasificaci√≥n por Edad
- **Valores**: 1-6 (Everyone, Teen, Mature, etc.)
- **Justificaci√≥n**: Define el mercado objetivo
- **Correlaci√≥n con √©xito**: 0.156
- **Distribuci√≥n**: Everyone (40%), Teen (30%), Mature (25%)

#### 5. **`estimated_hours`** - Horas de Juego Estimadas
- **Rango**: 0-200+ horas
- **Justificaci√≥n**: Duraci√≥n afecta percepci√≥n de valor
- **Correlaci√≥n con √©xito**: 0.198
- **Distribuci√≥n**: Mediana ~12 horas, Media ~18 horas

#### 6. **`planned_year`** - A√±o de Lanzamiento Planeado
- **Rango**: 2010-2024
- **Justificaci√≥n**: Tendencias temporales del mercado
- **Correlaci√≥n con √©xito**: -0.089 (juegos recientes ligeramente menos exitosos)

### Features Descartadas
- **`metacritic`**: No disponible antes del lanzamiento
- **`reviews_count`**: Resultado del √©xito, no predictor
- **`added`**: M√©trica post-lanzamiento
- **`beaten/dropped`**: Datos de comportamiento post-lanzamiento

---

## üéØ Definici√≥n de Variables Target

### Opciones Evaluadas

#### 1. **`success_score`** (SELECCIONADA) - Variable Continua
```sql
success_score = (
  (rating / 5.0 * 0.25) +                    -- 25% Calidad percibida
  (LOG(added + 1) / LOG(10000) * 0.20) +     -- 20% Popularidad
  (LOG(beaten + 1) / LOG(1000) * 0.20) +     -- 20% Completitud
  (retention_score / 100.0 * 0.20) +         -- 20% Retenci√≥n
  (LOG(engagement + 1) / LOG(5000) * 0.10) + -- 10% Engagement total
  (metacritic / 100.0 * 0.05)                -- 5% Cr√≠tica especializada
)
```

**Ventajas**:
- ‚úÖ **Informaci√≥n granular**: Valores continuos 0-1
- ‚úÖ **Flexibilidad**: Permite diferentes umbrales de √©xito
- ‚úÖ **Ranking**: Ordena juegos por probabilidad de √©xito
- ‚úÖ **Combina m√∫ltiples m√©tricas**: Visi√≥n hol√≠stica del √©xito

#### 2. **`success_category`** - Variable Categ√≥rica
- `high_success`: Rating ‚â•4.5, Beaten ‚â•1000, Retenci√≥n ‚â•70%
- `moderate_success`: Rating ‚â•4.0, Beaten ‚â•500, Retenci√≥n ‚â•60%
- `low_success`: Rating ‚â•3.5, Beaten ‚â•100, Retenci√≥n ‚â•40%
- `failure`: Dropped > Beaten*2 y Rating <3.0
- `neutral`: El resto

#### 3. **`is_successful`** - Variable Binaria
- `1`: Rating ‚â•3.5 Y Beaten ‚â•100
- `0`: Caso contrario

### Justificaci√≥n de la Selecci√≥n
Se eligi√≥ **`success_score`** porque:
1. **M√°xima informaci√≥n**: Aprovecha toda la granularidad de los datos
2. **Interpretabilidad**: Score 0-1 f√°cil de entender
3. **Flexibilidad post-modelo**: Se pueden definir umbrales despu√©s
4. **Mejor para optimizaci√≥n**: Los algoritmos de regresi√≥n pueden encontrar patrones m√°s sutiles

---

## ü§ñ Selecci√≥n de Modelos

### Criterios de Evaluaci√≥n
1. **Rendimiento predictivo**: RMSE, MAE, R¬≤
2. **Interpretabilidad**: Importancia de features
3. **Velocidad**: Tiempo de entrenamiento y predicci√≥n
4. **Robustez**: Manejo de outliers y overfitting
5. **Facilidad de implementaci√≥n**: Complejidad de deployment

### Modelos Evaluados

#### 1. **XGBoost** (RECOMENDADO PRINCIPAL)
```python
XGBRegressor(
    n_estimators=500,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.9,
    colsample_bytree=0.9
)
```

**Ventajas**:
- ‚úÖ **Excelente con datos tabulares**: Optimizado para este tipo de problemas
- ‚úÖ **Manejo autom√°tico**: Features categ√≥ricas y num√©ricas
- ‚úÖ **Robusto**: Resistente a outliers y overfitting
- ‚úÖ **Interpretable**: Feature importance nativa
- ‚úÖ **R√°pido**: Entrenamiento y predicci√≥n eficientes
- ‚úÖ **Hyperparameter tuning**: GridSearch implementado

**Desventajas**:
- ‚ùå **Complejidad**: Muchos hiperpar√°metros
- ‚ùå **Memoria**: Puede ser intensivo en memoria

#### 2. **Red Neuronal** (EXPERIMENTAL)
```python
Sequential([
    Dense(128, activation='relu'),
    BatchNormalization(),
    Dropout(0.3),
    Dense(64, activation='relu'),
    BatchNormalization(), 
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(16, activation='relu'),
    Dropout(0.1),
    Dense(1, activation='sigmoid')
])
```

**Ventajas**:
- ‚úÖ **Interacciones complejas**: Puede capturar relaciones no lineales
- ‚úÖ **Escalabilidad**: Maneja bien datasets grandes
- ‚úÖ **Flexibilidad**: Arquitectura personalizable
- ‚úÖ **Early stopping**: Prevenci√≥n de overfitting

**Desventajas**:
- ‚ùå **Caja negra**: Menos interpretable
- ‚ùå **Hiperpar√°metros**: Muchos par√°metros a ajustar
- ‚ùå **Datos**: Necesita m√°s datos para generalizar bien
- ‚ùå **Tiempo**: Entrenamiento m√°s lento

#### 3. **Random Forest** (BASELINE)
```python
RandomForestRegressor(
    n_estimators=300,
    max_depth=10,
    random_state=42
)
```

**Ventajas**:
- ‚úÖ **Estable**: Muy confiable y predecible
- ‚úÖ **Sin overfitting**: Resistente por naturaleza
- ‚úÖ **Interpretable**: Feature importance clara
- ‚úÖ **F√°cil de usar**: Pocos hiperpar√°metros

**Desventajas**:
- ‚ùå **Rendimiento**: Generalmente inferior a XGBoost
- ‚ùå **Memoria**: Puede ser intensivo con muchos √°rboles

### Predicci√≥n de Rendimiento
Basado en caracter√≠sticas del dataset y literatura:

| Modelo | RMSE Esperado | R¬≤ Esperado | Interpretabilidad | Velocidad |
|--------|---------------|-------------|-------------------|-----------|
| XGBoost | 0.024-0.028 | 0.82-0.86 | Alta | Alta |
| Neural Network | 0.026-0.032 | 0.78-0.84 | Baja | Media |
| Random Forest | 0.028-0.035 | 0.76-0.82 | Alta | Alta |

---

## üîÑ Pipeline de Entrenamiento

### Arquitectura del Pipeline

#### 1. **Carga y Validaci√≥n de Datos**
```python
def load_and_prepare_data():
    # Soporte m√∫ltiples formatos: CSV, Parquet, Pickle
    # Validaci√≥n de columnas requeridas
    # Manejo de valores faltantes
    # Estad√≠sticas b√°sicas de validaci√≥n
```

#### 2. **Divisi√≥n de Datos**
- **Entrenamiento**: 70% (~53,000 juegos)
- **Validaci√≥n**: 10% (~7,600 juegos)  
- **Test**: 20% (~15,200 juegos)

#### 3. **Preprocesamiento**
```python
# Para modelos tree-based (XGBoost, RF): Sin escalado
# Para Neural Network: StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

#### 4. **Entrenamiento con Validaci√≥n**
- **XGBoost**: GridSearchCV opcional con 3-fold CV
- **Neural Network**: Early stopping + ReduceLROnPlateau
- **Random Forest**: Par√°metros por defecto optimizados

#### 5. **Evaluaci√≥n Comprehensiva**
```python
metrics = {
    'RMSE': Root Mean Square Error,
    'MAE': Mean Absolute Error, 
    'R¬≤': R-squared Score
}
```

#### 6. **Visualizaciones**
- Comparaci√≥n de modelos (RMSE, R¬≤)
- Feature importance (XGBoost, RF)
- Predictions vs Actual (scatter plots)
- Training history (Neural Network)

#### 7. **Guardado de Modelos**
- `xgboost_model.json`: Modelo XGBoost
- `neural_network_model.h5`: Red neuronal
- `feature_scaler.pkl`: Escalador de features

### Configuraci√≥n para Kaggle
```python
# Detecci√≥n autom√°tica de rutas de datos
possible_paths = [
    "/kaggle/input/rawg-games/training_dataset.csv",
    "/kaggle/input/rawg-games/training_dataset.parquet",
    "training_dataset.csv"
]

# Configuraci√≥n de hiperpar√°metros
TUNE_HYPERPARAMS = False  # True para tuning completo
```

---

## üìä Resultados y Conclusiones

### Filtros de Calidad Aplicados
El dataset final contiene **76,000 juegos** despu√©s de aplicar:

1. **`released IS NOT NULL`**: Excluye juegos sin fecha de lanzamiento
2. **`rating IS NOT NULL`**: Excluye juegos sin rating v√°lido  
3. **`added > 0`**: Solo juegos con engagement de usuarios
4. **`EXTRACT(YEAR FROM released) BETWEEN 2010 AND 2024`**: Rango temporal relevante

### Justificaci√≥n de Filtros
- **Calidad sobre cantidad**: Mejor tener datos confiables que muchos datos ruidosos
- **Relevancia temporal**: Juegos muy antiguos pueden no ser representativos del mercado actual
- **Engagement m√≠nimo**: Juegos sin usuarios no proporcionan se√±al √∫til

### Distribuci√≥n Final del Target
```
success_score estad√≠sticas:
- Media: 0.234
- Mediana: 0.198  
- Desviaci√≥n est√°ndar: 0.156
- Rango: 0.000 - 0.987
```

### Features M√°s Predictivas (Esperadas)
1. **`n_platforms`**: Alcance de mercado
2. **`estimated_hours`**: Percepci√≥n de valor
3. **`n_genres`**: Definici√≥n de audiencia
4. **`planned_year`**: Tendencias temporales
5. **`esrb_rating_id`**: Segmentaci√≥n de mercado
6. **`n_tags`**: Riqueza de caracter√≠sticas

### Casos de Uso del Modelo
1. **Pre-producci√≥n**: Evaluar conceptos de juegos
2. **Planificaci√≥n**: Asignar recursos de desarrollo
3. **Marketing**: Definir estrategias de promoci√≥n
4. **Portfolio**: Balancear riesgo en cat√°logo de juegos

---

## üìÅ Archivos del Proyecto

### Estructura de Directorios
```
Proyecto-RAWG/
‚îú‚îÄ‚îÄ Data/
‚îÇ   ‚îú‚îÄ‚îÄ training_dataset.csv          # Dataset principal
‚îÇ   ‚îú‚îÄ‚îÄ training_dataset.parquet      # Versi√≥n optimizada
‚îÇ   ‚îî‚îÄ‚îÄ design_features_dataset.csv   # Solo features de dise√±o
‚îú‚îÄ‚îÄ Scripts/
‚îÇ   ‚îî‚îÄ‚îÄ train_models_kaggle.py        # Pipeline de entrenamiento
‚îú‚îÄ‚îÄ Notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ eda_rawg_games.ipynb         # An√°lisis exploratorio
‚îú‚îÄ‚îÄ Documentation/
‚îÇ   ‚îú‚îÄ‚îÄ project_documentation.md      # Este documento
‚îÇ   ‚îî‚îÄ‚îÄ roadmap_success_prediction.md # Roadmap original
‚îî‚îÄ‚îÄ Models/ (generado tras entrenamiento)
    ‚îú‚îÄ‚îÄ xgboost_model.json
    ‚îú‚îÄ‚îÄ neural_network_model.h5
    ‚îî‚îÄ‚îÄ feature_scaler.pkl
```

### Archivos Clave

#### **`training_dataset.csv`** - Dataset Principal
- **Filas**: 76,000 juegos
- **Columnas**: 25 (6 features + target + metadatos)
- **Tama√±o**: ~15 MB
- **Formato**: CSV con headers

#### **`train_models_kaggle.py`** - Script de Entrenamiento
- **L√≠neas**: 450 l√≠neas de c√≥digo
- **Funcionalidad**: Pipeline completo automatizado
- **Modelos**: XGBoost, Neural Network, Random Forest
- **Output**: Modelos entrenados + visualizaciones

#### **`eda_rawg_games.ipynb`** - Notebook de EDA
- **Celdas**: ~50 celdas
- **Contenido**: An√°lisis exploratorio completo
- **Visualizaciones**: 15+ gr√°ficos y tablas
- **Consultas SQL**: 20+ consultas optimizadas

### Dependencias del Proyecto
```python
# Librer√≠as principales
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
xgboost>=1.5.0
tensorflow>=2.8.0
matplotlib>=3.5.0
seaborn>=0.11.0

# Librer√≠as de soporte
sqlalchemy>=1.4.0
psycopg2-binary>=2.9.0
python-dotenv>=0.19.0
joblib>=1.1.0
```

---

## üöÄ Pr√≥ximos Pasos

### Mejoras Potenciales
1. **Feature Engineering Avanzado**:
   - Interacciones entre g√©neros y plataformas
   - Encoding de g√©neros espec√≠ficos m√°s populares
   - M√©tricas de competencia por a√±o/g√©nero

2. **Modelos M√°s Sofisticados**:
   - LightGBM para comparaci√≥n con XGBoost
   - CatBoost para manejo nativo de categ√≥ricas
   - Ensemble methods combinando m√∫ltiples modelos

3. **Validaci√≥n Temporal**:
   - Split por a√±o para validar predicci√≥n temporal
   - An√°lisis de drift en el tiempo
   - Recalibraci√≥n peri√≥dica del modelo

4. **Deployment**:
   - API REST para predicciones en tiempo real
   - Dashboard interactivo para dise√±adores
   - Integraci√≥n con herramientas de desarrollo

### M√©tricas de √âxito del Proyecto
- **RMSE < 0.030**: Error aceptable para decisiones de negocio
- **R¬≤ > 0.80**: Explicaci√≥n suficiente de la varianza
- **Interpretabilidad**: Features importance claras y accionables
- **Velocidad**: Predicciones en <100ms para uso interactivo

---

## üë• Contacto y Mantenimiento

**Autor**: Alex G. Herrera  
**Proyecto**: RAWG Game Success Prediction  
**Fecha**: Agosto 2024  
**Versi√≥n**: 1.0

**Para actualizaciones del modelo**:
1. Ejecutar EDA con datos m√°s recientes
2. Re-entrenar con pipeline existente
3. Validar performance en datos nuevos
4. Actualizar modelos en producci√≥n

---

*Este documento representa el estado completo del proyecto de predicci√≥n de √©xito de videojuegos basado en caracter√≠sticas de dise√±o, desde la exploraci√≥n inicial hasta la implementaci√≥n del pipeline de entrenamiento.*
