{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f605fa",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Análisis de Correlaciones y Distribuciones - Dataset v3\n",
    "\n",
    "## Objetivo\n",
    "Analizar en profundidad el dataset generado por el EDA v3 para:\n",
    "1. Identificar el problema del desbalance extremo de clases\n",
    "2. Analizar correlaciones entre features y target\n",
    "3. Evaluar distribuciones de variables\n",
    "4. Proponer soluciones concretas para el desbalance\n",
    "5. Redefinir criterios de éxito si es necesario\n",
    "\n",
    "## Problema Identificado\n",
    "- High Success: 0.7% (461 juegos)\n",
    "- Moderate Success: 8.0% (5,103 juegos) \n",
    "- Low Success: 91.3% (58,551 juegos)\n",
    "\n",
    "Este desbalance extremo explica el ceiling de ~50% accuracy en versiones anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff05ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f46fe",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Paso 1: Carga y Exploración Inicial del Dataset\n",
    "\n",
    "### Objetivo\n",
    "Cargar el dataset v3 y realizar una exploración inicial para confirmar el problema de desbalance y entender la estructura de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c3e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset v3\n",
    "df = pd.read_csv('../data/classification_dataset_v3.csv')\n",
    "\n",
    "print(\"=== INFORMACIÓN BÁSICA DEL DATASET ===\")\n",
    "print(f\"Dimensiones: {df.shape}\")\n",
    "print(f\"Columnas: {len(df.columns)}\")\n",
    "print(f\"Filas: {len(df):,}\")\n",
    "\n",
    "print(\"\\n=== DISTRIBUCIÓN DE LA VARIABLE OBJETIVO ===\")\n",
    "target_dist = df['success_category'].value_counts()\n",
    "target_pct = df['success_category'].value_counts(normalize=True) * 100\n",
    "\n",
    "for category in target_dist.index:\n",
    "    count = target_dist[category]\n",
    "    pct = target_pct[category]\n",
    "    print(f\"{category}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== INFORMACIÓN DE COLUMNAS ===\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15424b3",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Paso 2: Análisis Detallado del Desbalance de Clases\n",
    "\n",
    "### Objetivo\n",
    "Visualizar y cuantificar el problema del desbalance para entender su magnitud y proponer soluciones específicas.\n",
    "\n",
    "### Metodología\n",
    "- Visualización de distribución de clases\n",
    "- Cálculo de ratios de desbalance\n",
    "- Análisis de implicaciones para modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52370297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización del desbalance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Gráfico de barras\n",
    "target_dist.plot(kind='bar', ax=axes[0], color=['#ff7f7f', '#ffb347', '#90ee90'])\n",
    "axes[0].set_title('Distribución de Categorías de Éxito', fontweight='bold')\n",
    "axes[0].set_xlabel('Categoría de Éxito')\n",
    "axes[0].set_ylabel('Número de Juegos')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Añadir etiquetas con porcentajes\n",
    "for i, (category, count) in enumerate(target_dist.items()):\n",
    "    pct = target_pct[category]\n",
    "    axes[0].text(i, count + 1000, f'{count:,}\\n({pct:.1f}%)', \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gráfico de pastel\n",
    "axes[1].pie(target_dist.values, labels=target_dist.index, autopct='%1.1f%%',\n",
    "           colors=['#ff7f7f', '#ffb347', '#90ee90'])\n",
    "axes[1].set_title('Proporción de Categorías de Éxito', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cálculos de desbalance\n",
    "print(\"=== ANÁLISIS DE DESBALANCE ===\")\n",
    "total_games = len(df)\n",
    "high_success_ratio = target_dist['high_success'] / total_games\n",
    "moderate_success_ratio = target_dist['moderate_success'] / total_games\n",
    "low_success_ratio = target_dist['low_success'] / total_games\n",
    "\n",
    "print(f\"Ratio High Success: 1:{int(1/high_success_ratio)}\")\n",
    "print(f\"Ratio Moderate Success: 1:{int(1/moderate_success_ratio)}\")\n",
    "print(f\"Ratio Low Success: 1:{int(1/low_success_ratio)}\")\n",
    "\n",
    "print(f\"\\nClase minoritaria (high_success): {high_success_ratio:.3f} ({high_success_ratio*100:.1f}%)\")\n",
    "print(f\"Desbalance extremo: {low_success_ratio/high_success_ratio:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb106d",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Paso 3: Análisis de Correlaciones entre Features\n",
    "\n",
    "### Objetivo\n",
    "Identificar qué features tienen mayor correlación con el éxito y detectar posibles redundancias entre variables.\n",
    "\n",
    "### Metodología\n",
    "- Matriz de correlación completa\n",
    "- Correlaciones específicas con la variable objetivo\n",
    "- Identificación de features más predictivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para correlación (convertir categórica a numérica)\n",
    "df_corr = df.copy()\n",
    "df_corr['success_numeric'] = df_corr['success_category'].map({\n",
    "    'low_success': 0,\n",
    "    'moderate_success': 1, \n",
    "    'high_success': 2\n",
    "})\n",
    "\n",
    "# Seleccionar solo columnas numéricas para correlación\n",
    "numeric_cols = df_corr.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_cols.remove('success_numeric')  # Remover para análisis separado\n",
    "\n",
    "# Matriz de correlación\n",
    "corr_matrix = df_corr[numeric_cols + ['success_numeric']].corr()\n",
    "\n",
    "# Visualización de matriz de correlación\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0,\n",
    "            square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Matriz de Correlación - Features vs Success', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlaciones específicas con success\n",
    "success_correlations = corr_matrix['success_numeric'].drop('success_numeric').sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"=== TOP 10 CORRELACIONES CON ÉXITO ===\")\n",
    "for feature, corr in success_correlations.head(10).items():\n",
    "    print(f\"{feature}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\n=== CORRELACIONES NEGATIVAS MÁS FUERTES ===\")\n",
    "negative_corrs = success_correlations[success_correlations < 0].head(5)\n",
    "for feature, corr in negative_corrs.items():\n",
    "    print(f\"{feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be3b3b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Paso 4: Análisis de Distribuciones de Features Clave\n",
    "\n",
    "### Objetivo\n",
    "Analizar las distribuciones de las features más correlacionadas con el éxito para entender patrones y posibles transformaciones.\n",
    "\n",
    "### Metodología\n",
    "- Histogramas de features numéricas clave\n",
    "- Análisis de features binarias por categoría de éxito\n",
    "- Identificación de patrones discriminativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de features numéricas clave\n",
    "numeric_features = ['n_genres', 'n_platforms', 'n_tags', 'release_year', 'playtime']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(numeric_features):\n",
    "    if i < len(axes):\n",
    "        # Histograma por categoría de éxito\n",
    "        for category in df['success_category'].unique():\n",
    "            subset = df[df['success_category'] == category][feature].dropna()\n",
    "            axes[i].hist(subset, alpha=0.6, label=category, bins=20)\n",
    "        \n",
    "        axes[i].set_title(f'Distribución de {feature}', fontweight='bold')\n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_ylabel('Frecuencia')\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Remover subplot vacío\n",
    "if len(numeric_features) < len(axes):\n",
    "    fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estadísticas descriptivas por categoría\n",
    "print(\"=== ESTADÍSTICAS DESCRIPTIVAS POR CATEGORÍA DE ÉXITO ===\")\n",
    "for feature in numeric_features:\n",
    "    print(f\"\\n--- {feature.upper()} ---\")\n",
    "    stats = df.groupby('success_category')[feature].agg(['count', 'mean', 'median', 'std']).round(2)\n",
    "    print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a00ffa",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Paso 5: Análisis de Features Binarias Específicas\n",
    "\n",
    "### Objetivo\n",
    "Analizar el comportamiento de las features binarias (géneros, plataformas, tags específicos) para identificar cuáles son más discriminativas.\n",
    "\n",
    "### Metodología\n",
    "- Análisis de frecuencia de features binarias por categoría\n",
    "- Test de chi-cuadrado para significancia estadística\n",
    "- Identificación de features más predictivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7002b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar features binarias\n",
    "binary_features = [col for col in df.columns if col.startswith('is_')]\n",
    "\n",
    "# Análisis de features binarias más discriminativas\n",
    "print(\"=== ANÁLISIS DE FEATURES BINARIAS ===\")\n",
    "binary_analysis = []\n",
    "\n",
    "for feature in binary_features:\n",
    "    # Tabla de contingencia\n",
    "    contingency = pd.crosstab(df[feature], df['success_category'])\n",
    "    \n",
    "    # Test chi-cuadrado\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "    \n",
    "    # Porcentajes por categoría\n",
    "    percentages = pd.crosstab(df[feature], df['success_category'], normalize='columns') * 100\n",
    "    \n",
    "    # Guardar resultados\n",
    "    binary_analysis.append({\n",
    "        'feature': feature,\n",
    "        'chi2': chi2,\n",
    "        'p_value': p_value,\n",
    "        'high_success_pct': percentages.loc[1, 'high_success'] if 1 in percentages.index else 0,\n",
    "        'moderate_success_pct': percentages.loc[1, 'moderate_success'] if 1 in percentages.index else 0,\n",
    "        'low_success_pct': percentages.loc[1, 'low_success'] if 1 in percentages.index else 0\n",
    "    })\n",
    "\n",
    "# Convertir a DataFrame y ordenar por chi-cuadrado\n",
    "binary_df = pd.DataFrame(binary_analysis)\n",
    "binary_df = binary_df.sort_values('chi2', ascending=False)\n",
    "\n",
    "print(\"TOP 10 FEATURES BINARIAS MÁS DISCRIMINATIVAS:\")\n",
    "print(binary_df.head(10)[['feature', 'chi2', 'p_value', 'high_success_pct', 'moderate_success_pct', 'low_success_pct']].round(3))\n",
    "\n",
    "# Visualización de top features binarias\n",
    "top_binary_features = binary_df.head(6)['feature'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(top_binary_features):\n",
    "    contingency = pd.crosstab(df[feature], df['success_category'])\n",
    "    percentages = pd.crosstab(df[feature], df['success_category'], normalize='columns') * 100\n",
    "    \n",
    "    percentages.T.plot(kind='bar', ax=axes[i], color=['lightcoral', 'lightblue'])\n",
    "    axes[i].set_title(f'{feature}\\n(Chi2: {binary_df[binary_df.feature==feature].chi2.iloc[0]:.1f})', \n",
    "                     fontweight='bold')\n",
    "    axes[i].set_xlabel('Categoría de Éxito')\n",
    "    axes[i].set_ylabel('Porcentaje')\n",
    "    axes[i].legend(['No tiene', 'Tiene'], loc='upper right')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c4ed3c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Paso 6: Propuestas Concretas para Solucionar el Desbalance\n",
    "\n",
    "### Objetivo\n",
    "Basándose en el análisis realizado, proponer soluciones específicas para el problema de desbalance que permitan alcanzar el objetivo de 80% accuracy.\n",
    "\n",
    "### Metodología\n",
    "- Evaluar diferentes estrategias de rebalanceo\n",
    "- Proponer nuevos criterios de definición de éxito\n",
    "- Recomendar técnicas de modelado apropiadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PROPUESTAS PARA SOLUCIONAR EL DESBALANCE ===\")\n",
    "\n",
    "print(\"\\n1. REFORMULACIÓN DEL TARGET (RECOMENDADO)\")\n",
    "print(\"   Opción A: Target Binario\")\n",
    "print(\"   - Success (moderate + high): 8.7%\")\n",
    "print(\"   - No Success (low): 91.3%\")\n",
    "print(\"   - Ratio: 1:10.5 (más manejable que 1:130)\")\n",
    "\n",
    "print(\"\\n   Opción B: Nuevos Criterios de Éxito\")\n",
    "print(\"   - Bajar umbrales: Rating ≥3.5 + Added ≥500\")\n",
    "print(\"   - Crear distribución más balanceada naturalmente\")\n",
    "\n",
    "# Simular target binario\n",
    "df['success_binary'] = (df['success_category'].isin(['moderate_success', 'high_success'])).astype(int)\n",
    "binary_dist = df['success_binary'].value_counts()\n",
    "binary_pct = df['success_binary'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"\\n   SIMULACIÓN TARGET BINARIO:\")\n",
    "print(f\"   No Success (0): {binary_dist[0]:,} ({binary_pct[0]:.1f}%)\")\n",
    "print(f\"   Success (1): {binary_dist[1]:,} ({binary_pct[1]:.1f}%)\")\n",
    "print(f\"   Ratio: 1:{binary_dist[0]/binary_dist[1]:.1f}\")\n",
    "\n",
    "print(\"\\n2. TÉCNICAS DE BALANCEO DE CLASES\")\n",
    "print(\"   - SMOTE: Generar ejemplos sintéticos de clase minoritaria\")\n",
    "print(\"   - Class Weights: Penalizar más errores en clase minoritaria\")\n",
    "print(\"   - Undersampling: Reducir clase mayoritaria (no recomendado)\")\n",
    "print(\"   - Ensemble Methods: Combinar múltiples modelos balanceados\")\n",
    "\n",
    "print(\"\\n3. MÉTRICAS DE EVALUACIÓN APROPIADAS\")\n",
    "print(\"   - ROC-AUC: Mejor para datasets desbalanceados\")\n",
    "print(\"   - F1-Score: Balance entre precision y recall\")\n",
    "print(\"   - Precision-Recall AUC: Foco en clase minoritaria\")\n",
    "print(\"   - Balanced Accuracy: Promedio de sensitividad por clase\")\n",
    "\n",
    "print(\"\\n4. ENRIQUECIMIENTO DE FEATURES\")\n",
    "print(\"   - Features derivadas: ratios, interacciones\")\n",
    "print(\"   - Features temporales: tendencias por año\")\n",
    "print(\"   - Features de complejidad: combinaciones de categorías\")\n",
    "\n",
    "# Análisis de correlación con target binario\n",
    "binary_corr = df[numeric_cols + ['success_binary']].corr()['success_binary'].drop('success_binary')\n",
    "binary_corr = binary_corr.sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"\\n=== CORRELACIONES CON TARGET BINARIO ===\")\n",
    "print(\"Top 5 correlaciones positivas:\")\n",
    "for feature, corr in binary_corr.head(5).items():\n",
    "    print(f\"  {feature}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\nTop 5 correlaciones negativas:\")\n",
    "negative_binary = binary_corr[binary_corr < 0].head(5)\n",
    "for feature, corr in negative_binary.items():\n",
    "    print(f\"  {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce1258",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Conclusiones y Recomendaciones\n",
    "\n",
    "### Hallazgos Clave\n",
    "\n",
    "1. **Desbalance Extremo Confirmado**: \n",
    "   - Ratio 1:130 para high_success es inmanejable\n",
    "   - Explica directamente el ceiling de ~50% accuracy\n",
    "\n",
    "2. **Features Más Predictivas Identificadas**:\n",
    "   - Variables numéricas: playtime, n_tags, release_year\n",
    "   - Features binarias: Géneros y plataformas específicas con alta significancia estadística\n",
    "\n",
    "3. **Patrones Discriminativos**:\n",
    "   - Juegos exitosos tienden a tener más tags y mayor playtime\n",
    "   - Ciertas combinaciones de géneros/plataformas son más predictivas\n",
    "\n",
    "### Recomendación Principal\n",
    "\n",
    "**Reformular el target a clasificación binaria**:\n",
    "- Success: moderate_success + high_success (8.7%)\n",
    "- No Success: low_success (91.3%)\n",
    "- Ratio 1:10.5 es mucho más manejable\n",
    "\n",
    "### Próximos Pasos Sugeridos\n",
    "\n",
    "1. **Implementar target binario** y regenerar dataset\n",
    "2. **Aplicar SMOTE** para balancear clases\n",
    "3. **Entrenar modelos** con class weights apropiados\n",
    "4. **Usar métricas correctas**: ROC-AUC, F1-Score\n",
    "5. **Validar** con estratificación de clases\n",
    "\n",
    "Con estas modificaciones, el objetivo de 80% accuracy se vuelve alcanzable."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
