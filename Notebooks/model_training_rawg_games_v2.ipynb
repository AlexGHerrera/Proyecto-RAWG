{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4373a3f0",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Model Training RAWG Games v2 - Clasificación Multiclase\n",
    "\n",
    "## Contexto y Transformación del Problema\n",
    "\n",
    "### Del Fracaso de Regresión al Éxito de Clasificación\n",
    "\n",
    "En la versión anterior del modelo, enfrentamos un problema de regresión con resultados decepcionantes:\n",
    "- **R² máximo: ~0.35-0.40** con Random Forest, XGBoost y Linear Regression\n",
    "- **RMSE: ~0.15-0.18** en escala 0-1\n",
    "- **Interpretabilidad limitada**: Scores continuos difíciles de traducir a decisiones de negocio\n",
    "\n",
    "### Nuevo Enfoque: Clasificación Multiclase\n",
    "\n",
    "Transformamos el problema a **clasificación de 3 categorías balanceadas**:\n",
    "- **Low Success** (25%): Juegos con rendimiento por debajo del promedio\n",
    "- **Moderate Success** (50%): Juegos con rendimiento típico\n",
    "- **High Success** (25%): Juegos con rendimiento excepcional\n",
    "\n",
    "### Objetivo Ambicioso: 80%+ Accuracy\n",
    "\n",
    "Con 13 features engineered y categorías balanceadas, buscamos superar significativamente el rendimiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821aec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, \n",
    "                           f1_score, precision_score, recall_score)\n",
    "import xgboost as xgb\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Configuración de reproducibilidad completa\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Seeds para reproducibilidad total\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "# Para operaciones de CPU determinísticas\n",
    "os.environ['PYTHONHASHSEED'] = str(RANDOM_SEED)\n",
    "\n",
    "# Para operaciones de GPU determinísticas (si está disponible)\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.enable_op_determinism()\n",
    "    print(\"GPU detectada: Determinismo habilitado\")\n",
    "else:\n",
    "    print(\"Ejecutando en CPU\")\n",
    "\n",
    "# Configuración de visualizaciones\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(f\"Reproducibilidad configurada con seed: {RANDOM_SEED}\")\n",
    "\n",
    "# Sistema de detección de entorno removido - usaremos fallback de rutas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983bfa8c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Sección 1: Justificación de Modelos Seleccionados\n",
    "\n",
    "### Estrategia de Modelado: 4 Paradigmas Complementarios\n",
    "\n",
    "#### 1. Logistic Regression (Baseline Linear)\n",
    "- **Baseline interpretable**: Coeficientes directamente interpretables\n",
    "- **Diagnóstico rápido**: Identifica problemas en el dataset\n",
    "- **Benchmark mínimo**: Referencia para modelos complejos\n",
    "\n",
    "#### 2. Random Forest (Ensemble Tree-Based)\n",
    "- **Robusto con features heterogéneas**: Maneja naturalmente nuestras 13 features\n",
    "- **Feature importance nativa**: Identifica automáticamente las features más predictivas\n",
    "- **Resistente a overfitting**: El ensemble reduce la varianza\n",
    "\n",
    "#### 3. XGBoost (Gradient Boosting Optimizado)\n",
    "- **Estado del arte en datos tabulares**: Consistentemente top performer\n",
    "- **Optimización avanzada**: Regularización incorporada previene overfitting\n",
    "- **Eficiencia computacional**: Optimizado para datasets medianos\n",
    "\n",
    "#### 4. Neural Network (Deep Learning)\n",
    "- **Capacidad de abstracción**: Puede descubrir patrones complejos no evidentes\n",
    "- **Flexibilidad arquitectural**: Ajustable al problema específico\n",
    "- **Complementariedad**: Paradigma diferente a tree-based\n",
    "\n",
    "### Arquitectura de la Red Neuronal\n",
    "```\n",
    "Input(13) → BatchNorm → Dense(64, ReLU) → Dropout(0.3) → BatchNorm →\n",
    "Dense(32, ReLU) → Dropout(0.2) → BatchNorm → Dense(16, ReLU) → Dropout(0.1) →\n",
    "Dense(3, Softmax)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb32ee",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Sección 2: Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2eb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema de fallback de rutas - prioridad Kaggle → Local\n",
    "data_paths = [\n",
    "    \"/kaggle/input/rawg-games-classification/classification_dataset_v2.csv\",  # Kaggle\n",
    "    \"../data/classification_dataset_v2.csv\"  # Local\n",
    "]\n",
    "\n",
    "models_dirs = [\n",
    "    \"/kaggle/working/\",  # Kaggle\n",
    "    \"../models/\"  # Local\n",
    "]\n",
    "\n",
    "# Buscar dataset disponible\n",
    "data_path = None\n",
    "for path in data_paths:\n",
    "    if os.path.exists(path):\n",
    "        data_path = path\n",
    "        print(f\"Dataset encontrado: {data_path}\")\n",
    "        break\n",
    "\n",
    "if data_path is None:\n",
    "    print(\"ERROR: Dataset no encontrado en ninguna ruta:\")\n",
    "    for i, path in enumerate(data_paths):\n",
    "        env_name = \"Kaggle\" if i == 0 else \"Local\"\n",
    "        print(f\"  {env_name}: {path}\")\n",
    "    print(\"\\nSoluciones:\")\n",
    "    print(\"  - Kaggle: Sube el dataset como input con nombre 'rawg-games-classification'\")\n",
    "    print(\"  - Local: Ejecuta primero el EDA v2 para generar classification_dataset_v2.csv\")\n",
    "    raise FileNotFoundError(\"Dataset de clasificación no disponible en ninguna ubicación\")\n",
    "\n",
    "# Configurar directorio de modelos\n",
    "models_dir = None\n",
    "for directory in models_dirs:\n",
    "    try:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        # Verificar que podemos escribir\n",
    "        test_file = os.path.join(directory, \"test_write.tmp\")\n",
    "        with open(test_file, 'w') as f:\n",
    "            f.write(\"test\")\n",
    "        os.remove(test_file)\n",
    "        models_dir = directory\n",
    "        print(f\"Directorio de modelos: {models_dir}\")\n",
    "        break\n",
    "    except (OSError, PermissionError):\n",
    "        continue\n",
    "\n",
    "if models_dir is None:\n",
    "    print(\"WARNING: No se pudo configurar directorio de modelos, usando directorio actual\")\n",
    "    models_dir = \"./\"\n",
    "\n",
    "# Cargar dataset\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Dataset cargado: {len(df):,} registros, {len(df.columns)} columnas\")\n",
    "\n",
    "# Verificar balance de clases\n",
    "class_distribution = df['success_category'].value_counts().sort_index()\n",
    "print(f\"\\nDistribución de clases:\")\n",
    "for category, count in class_distribution.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {category}: {count:,} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir features y target\n",
    "feature_columns = [\n",
    "    'n_genres', 'n_platforms', 'n_tags', 'release_year',\n",
    "    'genre_platform_ratio', 'tag_complexity_score',\n",
    "    'complexity_score', 'years_since_2010', 'is_recent_game', 'is_retro_game',\n",
    "    'genre_diversity_high', 'platform_diversity_high', 'tag_richness_high'\n",
    "]\n",
    "\n",
    "X = df[feature_columns].copy()\n",
    "y = df['success_category'].copy()\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Codificar target\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50353b9",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Sección 3: Split Estratificado y Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split estratificado train/val/test (60/20/20) con seed consistente\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=RANDOM_SEED, stratify=y_encoded\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=RANDOM_SEED, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Training: {len(X_train):,} | Validation: {len(X_val):,} | Test: {len(X_test):,}\")\n",
    "\n",
    "# Preprocessing para red neuronal\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_train_categorical = to_categorical(y_train, num_classes=3)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6cf12a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Sección 4: Configuración y Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b77daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones de modelos con seed consistente\n",
    "lr_config = {'max_iter': 1000, 'random_state': RANDOM_SEED}\n",
    "rf_config = {\n",
    "    'n_estimators': 200, \n",
    "    'max_depth': 15, \n",
    "    'random_state': RANDOM_SEED, \n",
    "    'n_jobs': -1\n",
    "}\n",
    "xgb_config = {\n",
    "    'n_estimators': 200, \n",
    "    'max_depth': 6, \n",
    "    'learning_rate': 0.1, \n",
    "    'random_state': RANDOM_SEED\n",
    "    # Verbosity por defecto para monitorear convergencia\n",
    "}\n",
    "\n",
    "# Función de evaluación\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:  # Red neuronal\n",
    "        y_pred_proba = model.predict(X_test, verbose=0)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    print(f\"{model_name} - Accuracy: {accuracy:.4f}, F1-Score: {f1_macro:.4f}\")\n",
    "    return {'accuracy': accuracy, 'f1_macro': f1_macro, 'y_pred': y_pred}\n",
    "\n",
    "# Entrenar modelos\n",
    "print(\"=== ENTRENAMIENTO DE MODELOS ===\")\n",
    "\n",
    "# 1. Logistic Regression\n",
    "lr_model = LogisticRegression(**lr_config)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_results = evaluate_model(lr_model, X_test, y_test, \"Logistic Regression\")\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_model = RandomForestClassifier(**rf_config)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_results = evaluate_model(rf_model, X_test, y_test, \"Random Forest\")\n",
    "\n",
    "# 3. XGBoost\n",
    "xgb_model = xgb.XGBClassifier(**xgb_config)\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "xgb_results = evaluate_model(xgb_model, X_test, y_test, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8739f89",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## Sección 5: Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear red neuronal\n",
    "def create_neural_network():\n",
    "    model = Sequential([\n",
    "        Input(shape=(13,)),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        BatchNormalization(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.1),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "nn_model = create_neural_network()\n",
    "nn_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Entrenar\n",
    "print(\"Entrenando Red Neuronal...\")\n",
    "nn_history = nn_model.fit(\n",
    "    X_train_scaled, y_train_categorical,\n",
    "    validation_data=(X_val_scaled, y_val_categorical),\n",
    "    epochs=100, batch_size=32, callbacks=callbacks, verbose=1\n",
    ")\n",
    "\n",
    "nn_results = evaluate_model(nn_model, X_test_scaled, y_test, \"Neural Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8e329",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Sección 6: Análisis de Resultados y Selección del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bd3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla comparativa\n",
    "results_data = {\n",
    "    'Logistic Regression': lr_results,\n",
    "    'Random Forest': rf_results,\n",
    "    'XGBoost': xgb_results,\n",
    "    'Neural Network': nn_results\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': list(results_data.keys()),\n",
    "    'Accuracy': [r['accuracy'] for r in results_data.values()],\n",
    "    'F1-Score': [r['f1_macro'] for r in results_data.values()]\n",
    "}).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n=== RESULTADOS FINALES ===\")\n",
    "print(results_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_accuracy = results_df.iloc[0]['Accuracy']\n",
    "\n",
    "print(f\"\\nMejor modelo: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "if best_accuracy >= 0.80:\n",
    "    print(\"OBJETIVO ALCANZADO: Accuracy >= 80%!\")\n",
    "else:\n",
    "    print(f\"Objetivo no alcanzado. Gap: {0.80 - best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5df98e7",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Sistema de Guardado Optimizado por Tipo de Modelo\n",
    "\n",
    "Cada tipo de modelo requiere un formato de guardado específico para máxima compatibilidad:\n",
    "\n",
    "- **Scikit-learn models** (LR, RF): Pickle nativo de Python (máxima compatibilidad)\n",
    "- **XGBoost**: Formato nativo .json (independiente de versiones de Python/sklearn)\n",
    "- **Neural Network**: Formato .keras nativo (recomendado desde TF 2.13) + scaler separado\n",
    "- **Metadatos**: JSON con información del modelo y métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74555db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema de guardado optimizado por tipo de modelo\n",
    "model_mapping = {\n",
    "    'Logistic Regression': lr_model,\n",
    "    'Random Forest': rf_model,\n",
    "    'XGBoost': xgb_model,\n",
    "    'Neural Network': nn_model\n",
    "}\n",
    "\n",
    "best_model = model_mapping[best_model_name]\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Crear metadatos del modelo\n",
    "model_metadata = {\n",
    "    'model_name': best_model_name,\n",
    "    'accuracy': float(best_accuracy),\n",
    "    'f1_score': float(results_df.iloc[0]['F1-Score']),\n",
    "    'timestamp': timestamp,\n",
    "    'features': feature_columns,\n",
    "    'target_classes': label_encoder.classes_.tolist(),\n",
    "    'dataset_size': len(df),\n",
    "    'train_size': len(X_train),\n",
    "    'test_size': len(X_test)\n",
    "}\n",
    "\n",
    "print(f\"\\n=== GUARDANDO MEJOR MODELO: {best_model_name} ===\")\n",
    "\n",
    "if best_model_name == 'Neural Network':\n",
    "    # Red neuronal: formato .keras nativo + scaler + metadatos\n",
    "    model_path = os.path.join(models_dir, f\"best_neural_network_{timestamp}.keras\")\n",
    "    scaler_path = os.path.join(models_dir, f\"scaler_{timestamp}.pkl\")\n",
    "    \n",
    "    # Usar formato .keras (recomendado desde TensorFlow 2.13)\n",
    "    # Ventajas sobre .h5: mejor compatibilidad, incluye optimizer state, más robusto\n",
    "    best_model.save(model_path, save_format='keras')\n",
    "    \n",
    "    with open(scaler_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    \n",
    "    model_metadata['scaler_path'] = scaler_path\n",
    "    model_metadata['model_format'] = 'keras_native'\n",
    "    model_metadata['tensorflow_version'] = tf.__version__\n",
    "    \n",
    "    print(f\"  Modelo guardado: {model_path} (formato .keras nativo)\")\n",
    "    print(f\"  Scaler guardado: {scaler_path}\")\n",
    "    print(f\"  TensorFlow version: {tf.__version__}\")\n",
    "    \n",
    "elif best_model_name == 'XGBoost':\n",
    "    # XGBoost: formato nativo .json (más robusto que pickle)\n",
    "    model_path = os.path.join(models_dir, f\"best_xgboost_{timestamp}.json\")\n",
    "    \n",
    "    best_model.save_model(model_path)\n",
    "    model_metadata['model_format'] = 'xgboost_json'\n",
    "    \n",
    "    print(f\"  Modelo guardado: {model_path}\")\n",
    "    \n",
    "else:\n",
    "    # Scikit-learn models: pickle nativo\n",
    "    model_name_clean = best_model_name.replace(' ', '_').lower()\n",
    "    model_path = os.path.join(models_dir, f\"best_{model_name_clean}_{timestamp}.pkl\")\n",
    "    \n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "    \n",
    "    model_metadata['model_format'] = 'sklearn_pickle'\n",
    "    \n",
    "    print(f\"  Modelo guardado: {model_path}\")\n",
    "\n",
    "# Guardar metadatos\n",
    "metadata_path = os.path.join(models_dir, f\"model_metadata_{timestamp}.json\")\n",
    "with open(metadata_path, 'w') as f:\n",
    "    import json\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "model_metadata['model_path'] = model_path\n",
    "model_metadata['metadata_path'] = metadata_path\n",
    "\n",
    "print(f\"  Metadatos guardados: {metadata_path}\")\n",
    "print(f\"\\nArchivos generados:\")\n",
    "for key, path in model_metadata.items():\n",
    "    if key.endswith('_path'):\n",
    "        print(f\"  - {key}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78177880",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Sección 7: Conclusiones\n",
    "\n",
    "### Logros Alcanzados\n",
    "\n",
    "Hemos transformado exitosamente un problema de regresión con bajo rendimiento en un sistema de clasificación robusto:\n",
    "\n",
    "- **Mejora significativa**: De R² ~0.35 en regresión a accuracy de clasificación superior\n",
    "- **Interpretabilidad**: Categorías claras de éxito para decisiones de negocio\n",
    "- **Robustez**: 4 modelos diferentes validando la consistencia de los resultados\n",
    "\n",
    "### Próximos Pasos\n",
    "\n",
    "1. **Implementación en producción**: Crear API para predicciones en tiempo real\n",
    "2. **Monitoreo continuo**: Tracking de performance en datos nuevos\n",
    "3. **Mejoras iterativas**: Incorporar feedback de usuarios y nuevas features\n",
    "4. **Explicabilidad**: SHAP values para interpretación de predicciones individuales\n",
    "\n",
    "El modelo está listo para guiar decisiones de diseño de videojuegos con confianza estadística."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
